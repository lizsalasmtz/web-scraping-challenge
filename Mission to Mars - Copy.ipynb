{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping Mars information for website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main functions to scrape NASA webpages on Mars\n",
    "\n",
    "### This cell will become scrape_mars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time # use this to ensure that javascript elements load completely before soup.find returns empty objects\n",
    "\n",
    "\n",
    "# chromedriver.exe should be installed to the root folder; if not, update the path\n",
    "executable_path = {\"executable_path\":\"/chromedriver.exe\"} \n",
    "\n",
    "\n",
    "# initialize a browser (called from get_soup using 'with' so browser closes automatically after html extracted)\n",
    "def get_browser():\n",
    "    b = Browser(\"chrome\", **executable_path, headless=False)    \n",
    "    return b\n",
    "\n",
    "\n",
    "def get_soup(url, wait_time):\n",
    "    # only keep the browser open to get the soup\n",
    "    with get_browser() as browser:\n",
    "        browser.visit(url) \n",
    "        time.sleep(wait_time)           \n",
    "        html = browser.html\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    return soup\n",
    "\n",
    "\n",
    "# get the latest Mars news from https://mars.nasa.gov/news/\n",
    "# returns a list of dictionaries containing the 'title' of the article and its 'description'\n",
    "def get_latest_mars_news():\n",
    "    mars_news_soup = get_soup('https://mars.nasa.gov/news/', 1)\n",
    "\n",
    "    # -- create empty lists for the articles\n",
    "    title = []\n",
    "    description = []\n",
    "\n",
    "    # -- loop through 'ul' tags with class 'item_list'\n",
    "    for item in mars_news_soup.find(\"ul\", class_=\"item_list\"):\n",
    "        \n",
    "        # -- get the title in the h3 tag \n",
    "        title.append(item.find(\"h3\").text)\n",
    "        \n",
    "        # -- ... and the description in the 'div' tag with class 'item_list' \n",
    "        description.append(item.find(\"div\", class_=\"article_teaser_body\").text)\n",
    "        \n",
    "    # only return the first news article (remove [0] to get all)\n",
    "    return title[0], description[0]\n",
    "\n",
    "\n",
    "def get_jpl_mars_feature_image_url():\n",
    "    # get the soup object for the JPL Mars images\n",
    "    mars_images_soup = get_soup('https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars', 1)\n",
    "    \n",
    "    # -- get the relative path of the featured image\n",
    "    image_rel_path = mars_images_soup.find(\"article\", class_=\"carousel_item\")['style']\n",
    "    \n",
    "    # -- remove the extra text:\"background-image: url(\" at the start and \"');\" at the end \n",
    "    image_rel_path = image_rel_path[image_rel_path.find(\"url('\")+5:image_rel_path.find(\"');\")]\n",
    "    \n",
    "    # -- add the base URL\n",
    "    featured_image_url = 'https://www.jpl.nasa.gov' + image_rel_path\n",
    "    \n",
    "    return featured_image_url\n",
    "    \n",
    "\n",
    "def get_mars_facts():\n",
    "    facts_url = 'https://space-facts.com/mars/'\n",
    "\n",
    "    # read the html into pandas\n",
    "    facts_ds = pd.read_html(facts_url)\n",
    "\n",
    "    # create a dataframe with the first column of data (Mars) from the table\n",
    "    facts_df = pd.DataFrame(facts_ds[0])\n",
    "\n",
    "    # create an HTML string of the table without headers and an index \n",
    "    mars_facts_table_html = facts_df.to_html(header = False, index = False)\n",
    "        \n",
    "    return mars_facts_table_html\n",
    "\n",
    "def get_hemispheres():\n",
    "    hemispheres_soup = get_soup('https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars', 5)\n",
    "    \n",
    "    hemisphere_image_urls = []\n",
    "    hemispheres_main_url = 'https://astrogeology.usgs.gov'\n",
    "\n",
    "    for i in hemispheres_soup.find_all('div', class_='item'):\n",
    "        # open the URL and get soup of the new page \n",
    "        item_soup = get_soup(hemispheres_main_url + i.find('a', class_='itemLink product-item')['href'], 5)\n",
    "\n",
    "        # get the title from the h3 tag\n",
    "        title = i.find('h3').text\n",
    "\n",
    "        # get the text of the div tag with class downloads\n",
    "        download_soup = item_soup.find('div', class_='downloads')\n",
    "\n",
    "        # get both links from the downloads\n",
    "        links_soup = download_soup.find_all('a', target='_blank')\n",
    "\n",
    "        # get the second URL (to the original)\n",
    "        hemisphere_image_urls.append({'title':title,'img_url':links_soup[1]['href']})\n",
    "\n",
    "    # return first 4 hemispheres, change [0:3] to get more\n",
    "    return hemisphere_image_urls[0:3]\n",
    "\n",
    "\n",
    "# this is the main function that calls all the other functions and returns\n",
    "# the news, feature image URL, the facts and the hemisphere image URLs and titles\n",
    "# in one dictionary\n",
    "def scrape():\n",
    "    # get the news\n",
    "    _news_title, _news_description = get_latest_mars_news()\n",
    "    \n",
    "    # get the featured image URL\n",
    "    _featured_img = get_jpl_mars_feature_image_url()\n",
    "    \n",
    "    # get the facts HTML table\n",
    "    _facts = get_mars_facts()\n",
    "    \n",
    "    # get the hemisphere image URLs and titles\n",
    "    _hemispheres = get_hemispheres()\n",
    "    \n",
    "    # put everything into one dictionary and return it\n",
    "    scraped_data = {'news_title':_news_title, 'news_description':_news_description, 'featured_image': _featured_img, 'facts':_facts, 'hemisphere_images':_hemispheres}\n",
    "    \n",
    "    return scraped_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the get_latest_mars_news function to get NASA Mars news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A Martian Roundtrip: NASA's Perseverance Rover Sample Tubes\nMarvels of engineering, the rover's sample tubes must be tough enough to safely bring Red Planet samples on the long journey back to Earth in immaculate condition. \n"
     ]
    }
   ],
   "source": [
    "# Mars news\n",
    "news_title, news_description = get_latest_mars_news()\n",
    "print(news_title)\n",
    "print(news_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the get_jpl_mars_feature_image_url function to get the \n",
    "## featured JPL Mars space image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA17843-1920x1200.jpg\n"
     ]
    }
   ],
   "source": [
    "# Feature image\n",
    "feature_image = get_jpl_mars_feature_image_url()\n",
    "print(feature_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the get_mars_facts function to get table of Mars facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\n  <tbody>\n    <tr>\n      <td>Equatorial Diameter:</td>\n      <td>6,792 km</td>\n    </tr>\n    <tr>\n      <td>Polar Diameter:</td>\n      <td>6,752 km</td>\n    </tr>\n    <tr>\n      <td>Mass:</td>\n      <td>6.39 × 10^23 kg (0.11 Earths)</td>\n    </tr>\n    <tr>\n      <td>Moons:</td>\n      <td>2 (Phobos &amp; Deimos)</td>\n    </tr>\n    <tr>\n      <td>Orbit Distance:</td>\n      <td>227,943,824 km (1.38 AU)</td>\n    </tr>\n    <tr>\n      <td>Orbit Period:</td>\n      <td>687 days (1.9 years)</td>\n    </tr>\n    <tr>\n      <td>Surface Temperature:</td>\n      <td>-87 to -5 °C</td>\n    </tr>\n    <tr>\n      <td>First Record:</td>\n      <td>2nd millennium BC</td>\n    </tr>\n    <tr>\n      <td>Recorded By:</td>\n      <td>Egyptian astronomers</td>\n    </tr>\n  </tbody>\n</table>\n"
     ]
    }
   ],
   "source": [
    "# facts\n",
    "mars_facts_html = get_mars_facts()\n",
    "print(mars_facts_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the get_hemispheres function to get Mars hemispheres image URLs \n",
    "## and their descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "hemispheres = get_hemispheres()\n",
    "print(hemispheres)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the scrape function for getting all data in one dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'news_title': \"A Martian Roundtrip: NASA's Perseverance Rover Sample Tubes\", 'news_description': \"Marvels of engineering, the rover's sample tubes must be tough enough to safely bring Red Planet samples on the long journey back to Earth in immaculate condition. \", 'featured_image': 'https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA17843-1920x1200.jpg', 'facts': '<table border=\"1\" class=\"dataframe\">\\n  <tbody>\\n    <tr>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <td>Mass:</td>\\n      <td>6.39 × 10^23 kg (0.11 Earths)</td>\\n    </tr>\\n    <tr>\\n      <td>Moons:</td>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.38 AU)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <td>Surface Temperature:</td>\\n      <td>-87 to -5 °C</td>\\n    </tr>\\n    <tr>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>', 'hemisphere_images': []}\n"
     ]
    }
   ],
   "source": [
    "data = scrape()\n",
    "print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}